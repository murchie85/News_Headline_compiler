{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTLINE \n",
    "\n",
    "\n",
    "- Run job three times per day \n",
    "- Gets current date \n",
    "- Checks current date folder \n",
    "- compares news array to written files\n",
    "- If news array has items that are not in written files\n",
    "- Regenerate news array with missing items\n",
    "- call news api, get news for updated news array\n",
    "- Save to json  \n",
    "- Also save all files to csv (can overwrite)\n",
    "\n",
    "\n",
    "# MODIFICATION \n",
    "\n",
    "- Compare dataframes\n",
    "- no longer reducing news_array\n",
    "- simply removing anything that is already on file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2020-01-02\n",
      "Dir Already exists\n",
      "\n",
      "PULLING NEWS HEADLINES - PLEASE WAIT .... \n",
      "\n",
      "processing bbc-news headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing abc-news headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing cnn headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing fox-news headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing independent headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing mirror headlines\n",
      "Request for the mirror news source is empty, skipping\n",
      "\n",
      "processing metro headlines\n",
      "Request for the metro news source is empty, skipping\n",
      "\n",
      "processing daily-mail headlines\n",
      "Request for the daily-mail news source is empty, skipping\n",
      "\n",
      "processing Theguardian.com headlines\n",
      "Request for the Theguardian.com news source is empty, skipping\n",
      "\n",
      "processing Sky.com headlines\n",
      "Request for the Sky.com news source is empty, skipping\n",
      "\n",
      "processing the-new-york-times headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing al-jazeera-english headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing reuters headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing the-hill headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing breitbart-news headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing the-verge headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "processing the-huffington-post headlines\n",
      "COMPLETE - appending to array .......\n",
      "\n",
      "iterating through \n",
      "PROCESSING COMPLETE\n",
      "number of articles processed are : 108\n",
      "Appending old and new feeds\n",
      "\n",
      "describing new data\n",
      "(108, 8)\n",
      "\n",
      "describing old data\n",
      "(216, 8)\n",
      "describing merged data with dropped duplicates\n",
      "(117, 8)\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------------\n",
    "#\n",
    "# Program name : process_news.py\n",
    "# Program Created Date: 31 December 2019\n",
    "# Program Amanded Date: 02 Jan 2020\n",
    "# Program Author: Adam McMurchie\n",
    "#\n",
    "# Program Description:  This program iterrogates news.api, pulls data and consolodates in a re-occuring append fasion. The aim to \n",
    "#                       Overtime build a portfolio of news data from various sources. Various archival, and time delay considerations \n",
    "#                       have been baked into the code (explained in program flow).\n",
    "#\n",
    "# Input Files:     Data from news.api which is whatever was present 15 minutes ago. \n",
    "# Output Files:    Json files in data folder, output.csv full list in data folder\n",
    "#\n",
    "# Program Flow :  **to be updated** Run job three times per day (at least)\n",
    "#                  Gets current date\n",
    "#                  Checks current date data folder (create if not exist)\n",
    "#                  compares news array pulled from news.api to written files\n",
    "#                  If news array has items that are not in written files\n",
    "#                  Regenerate news array with missing items\n",
    "#                  call news api, get news for updated news array\n",
    "#                  Save to json\n",
    "#                  Also save all files to csv (can overwrite)\n",
    "#                  Saves crossing any wires or putting the wrong list in the wrong market\n",
    "#\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# IMPORT STATEMENTS \n",
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from newsapi import NewsApiClient\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORT API KEYS\n",
    "f = open(\"../keys/api.txt\", \"r\")\n",
    "keys = f.read()\n",
    "f.close()\n",
    "ACCESS_TOKEN = keys\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#   PARMS SECTION \n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "# READING IN \n",
    "NewsFileNameArray = []                         # A LIST OF FILENAMES \n",
    "data = []                                      # ALL NEWS DATA FROM LOCAL NEWS JSON FILES\n",
    "\n",
    "# REQUESTING NEW DATA\n",
    "newsapi = NewsApiClient(api_key=ACCESS_TOKEN)  # INITIALISING newsapi object\n",
    "news_keyname_array = ['bbc-news', 'abc-news','cnn','fox-news','independent','mirror','metro','daily-mail', 'Theguardian.com' , 'Sky.com', 'the-new-york-times', 'al-jazeera-english', 'reuters', 'the-hill' , 'breitbart-news', 'the-verge', 'the-huffington-post']\n",
    "news_array = []\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#   CREATE NEW FOLDER FOR TODAY IF NOT EXIST\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# GET TODAYS DATE \n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)\n",
    "\n",
    "# CREATE A NEW DIRECTORY FOR TODAY IF NOT EXIST\n",
    "if os.path.isdir(\"data/\" + str(today)):\n",
    "    print('Dir Already exists')\n",
    "else:\n",
    "    os.mkdir(\"data/\" + str(today))\n",
    "\n",
    "print('')\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#   REQUESTING MORE NEWS \n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "# Init API and save to news_array\n",
    "# WRITE TO JSON\n",
    "print('PULLING NEWS HEADLINES - PLEASE WAIT .... ')\n",
    "print('')\n",
    "for item in news_keyname_array:\n",
    "    print('processing ' + str(item + ' headlines'))\n",
    "    news_key = item\n",
    "    json_item = newsapi.get_top_headlines(sources=news_key)\n",
    "    if json_item['totalResults'] == 0:\n",
    "        print(\"Request for the \" + str(item) + \" news source is empty, skipping\")\n",
    "        print('')\n",
    "        continue\n",
    "    news_array.append(json_item)\n",
    "    print('COMPLETE - appending to array .......')\n",
    "    print('')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "#   BUILDING REPORT \n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "# BUILD A PANDAS DATA FRAME \n",
    "df = pd.DataFrame(columns=['source','author','title','description','url', 'requested_date','publishedAt','content'])\n",
    "\n",
    "\n",
    "# Iterate through DATA array and write to csv\n",
    "print('iterating through ')\n",
    "x = 0 \n",
    "for news_outlet in range (0, len(news_array)):\n",
    "    for article_number in range (0, len(news_array[news_outlet]['articles'])):\n",
    "        source         = news_array[news_outlet]['articles'][article_number]['source']['name']\n",
    "        author         = news_array[news_outlet]['articles'][article_number]['author']\n",
    "        title          = news_array[news_outlet]['articles'][article_number]['title']\n",
    "        description    = news_array[news_outlet]['articles'][article_number]['description']\n",
    "        url            = news_array[news_outlet]['articles'][article_number]['url']\n",
    "        publishedAt    = news_array[news_outlet]['articles'][article_number]['publishedAt']\n",
    "        requested_date = today\n",
    "        content        = news_array[news_outlet]['articles'][article_number]['content']\n",
    "        df = df.append([{ 'source': source, 'author': author, 'title': title, 'description': description, 'url':url, 'publishedAt': publishedAt, 'requested_date': requested_date, 'content': content    }])\n",
    "        x = x + 1 \n",
    "\n",
    "print('PROCESSING COMPLETE')\n",
    "print('number of articles processed are : ' + str(x))\n",
    "\n",
    "# imported is old data\n",
    "# df is the new data\n",
    "# combined is merged \n",
    "imported = pd.read_csv(\"data/\" + str(today) + \"/\" + 'output.csv', index_col=0)\n",
    "print('Appending old and new feeds')\n",
    "combined = imported.append(df)\n",
    "print('')\n",
    "combined = combined.drop_duplicates(subset=\"description\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('describing new data')\n",
    "print(df.shape)\n",
    "print('')\n",
    "print('describing old data')\n",
    "print(imported.shape)\n",
    "print('describing merged data with dropped duplicates')\n",
    "print(combined.shape)\n",
    "\n",
    "        \n",
    "#combined.to_csv(\"data/\" + str(today) + \"/\" + 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
